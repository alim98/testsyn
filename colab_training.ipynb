{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synapse Analysis Training in Colab\n",
    "\n",
    "This notebook provides a simple workflow for training models from the synapse analysis project in Google Colab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install transformers scikit-learn matplotlib seaborn torch torchvision umap-learn openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the repository\n",
    "!git clone https://github.com/alim98/testsyn.git\n",
    "%cd testsyn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download and Prepare Data\n",
    "\n",
    "If you've uploaded data files to Colab's file system, you can skip this section. Otherwise, download the data from Google Drive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive (if your data is there)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data directly from shared links if needed\n",
    "!wget -O downloaded_file.zip \"https://drive.usercontent.google.com/download?id=1iHPBdBOPEagvPTHZmrN__LD49emXwReY&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\"\n",
    "!wget -O vesicle_cloud__syn_interface__mitochondria_annotation.zip \"https://drive.usercontent.google.com/download?id=1qRibZL3kr7MQJQRgDFRquHMQlIGCN4XP&export=download&authuser=0&confirm=t&uuid=631d60dd-569c-4bb1-a9e8-d681f0ed3d43&at=APvzH3r4me8x_LwP3n8O7lgPo8oK%3A1733988188000\"\n",
    "\n",
    "# Unzip the data\n",
    "!unzip -q downloaded_file.zip -d /content/raw\n",
    "!unzip -q vesicle_cloud__syn_interface__mitochondria_annotation.zip -d /content/seg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Add Project Root to Python Path\n",
    "\n",
    "This ensures all imports work correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the current directory to the Python path\n",
    "if os.getcwd() not in sys.path:\n",
    "    sys.path.append(os.getcwd())\n",
    "\n",
    "# Create necessary directories if they don't exist\n",
    "os.makedirs('results', exist_ok=True)\n",
    "os.makedirs('output', exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extract Point Clouds\n",
    "\n",
    "Run the point cloud extraction script first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run point cloud extraction\n",
    "!python extract_point_clouds.py --raw_base_dir \"/content/raw\" --seg_base_dir \"/content/seg\" --add_mask_base_dir \"/content\" --output_path \"point_clouds.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train the Model\n",
    "\n",
    "Now run the training script:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import training function\n",
    "from train_with_point_clouds import train\n",
    "\n",
    "# Set up training arguments\n",
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.point_clouds_path = \"point_clouds.pkl\"\n",
    "        self.output_dir = \"output\"\n",
    "        self.batch_size = 16  # Adjust based on GPU memory\n",
    "        self.num_workers = 2\n",
    "        self.epochs = 50\n",
    "        self.learning_rate = 1e-4\n",
    "        self.weight_decay = 1e-4\n",
    "        self.encoder_dim = 512\n",
    "        self.projection_dim = 128\n",
    "        self.temperature = 0.1\n",
    "        self.use_dual_encoder = True  # Set to True to use both texture and shape encoders\n",
    "        self.max_points = 1024  # Maximum number of points in point cloud\n",
    "\n",
    "args = Args()\n",
    "\n",
    "# Run training\n",
    "train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate and Visualize Results\n",
    "\n",
    "After training, you can evaluate your model and visualize the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from models.contrastive_model import DualEncoderModel\n",
    "import numpy as np\n",
    "\n",
    "# Load your trained model\n",
    "model_path = os.path.join(args.output_dir, \"model_final.pth\")\n",
    "model = DualEncoderModel(\n",
    "    in_channels=1,\n",
    "    encoder_dim=args.encoder_dim,\n",
    "    projection_dim=args.projection_dim,\n",
    "    max_points=args.max_points\n",
    ")\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.eval()\n",
    "\n",
    "# Visualize the loss curve\n",
    "loss_path = os.path.join(args.output_dir, \"losses.npy\")\n",
    "if os.path.exists(loss_path):\n",
    "    losses = np.load(loss_path)\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(losses)\n",
    "    plt.title(\"Training Loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Save and Download Results\n",
    "\n",
    "Download the trained model and results to your local computer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the output directory\n",
    "!zip -r trained_model.zip output/\n",
    "\n",
    "# Download the zip file (will prompt in Colab)\n",
    "from google.colab import files\n",
    "files.download('trained_model.zip')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
} 